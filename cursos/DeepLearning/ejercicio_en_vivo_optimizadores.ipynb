{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N34R20/DeepLearningHumai/blob/main/ejercicio_en_vivo_optimizadores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxdxiIG1epiv"
      },
      "source": [
        "# Ejercicio en vivo clase 6: Optimizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TXnP-2bYYJI"
      },
      "source": [
        "# Consigna:\n",
        "\n",
        "Dadas las siguientes funciones y el modelo base, utilice KFold para evaluar cuál de los siguientes optimizadores arroja los mejores resultados para el dataset de FashionMNIST: [\"Adagrad\", \"RMSprop\", \"Adadelta\", \"Adam\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HX42-P0RXoAA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wpMom8YdhWK0"
      },
      "outputs": [],
      "source": [
        "#### Funciones necesarias de otros notebooks\n",
        "\n",
        "def reset_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())\n",
        "\n",
        "def get_accuracy(fold, model, device, test_loader):\n",
        "  TestAcc = 0.0\n",
        "  N = 0\n",
        "  for X, y in test_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      N += y.numel()\n",
        "      TestAcc += accuracy(model(X), y)\n",
        "  print('\\nFold {}:  Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        fold, TestAcc, N,\n",
        "        (100. * TestAcc) / N))\n",
        "  return TestAcc / N\n",
        "\n",
        "def train(fold, model, device, loss, train_loader, optimizer):\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      l = loss(model(data), target).mean()\n",
        "      l.backward()\n",
        "      optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VfZot8yBhZ5C"
      },
      "outputs": [],
      "source": [
        "### Función que lleva adelante el proceso de kfold cross validation\n",
        "def train_kfold(model, optimizer, dataset, n_fold, epochs):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "  optimizer = optimizer\n",
        "  batch_size=32\n",
        "  folds=n_fold\n",
        "  train_acc = []\n",
        "  acc = []\n",
        "  kfold=KFold(n_splits=n_fold,shuffle=True)\n",
        "  for fold,(train_idx,test_idx) in enumerate(kfold.split(dataset)):\n",
        "    print('------------fold no---------{}----------------------'.format(fold))\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "                        dataset,\n",
        "                        batch_size=batch_size, sampler=train_subsampler)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "                        dataset,\n",
        "                        batch_size=batch_size, sampler=test_subsampler)\n",
        "\n",
        "    model.apply(reset_weights)\n",
        "\n",
        "    fold_acc = 0\n",
        "    model.to(device=device)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "      train(fold, model, device, loss, trainloader, optimizer)\n",
        "      fold_train_acc = get_accuracy(fold, model, device, trainloader)\n",
        "      fold_acc =       get_accuracy(fold, model, device,  testloader)\n",
        "    train_acc.append(fold_train_acc)\n",
        "    acc.append(fold_acc)\n",
        "  return train_acc, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hMzA4NKmYi_Y"
      },
      "outputs": [],
      "source": [
        "# Estructura del modelo base\n",
        "INPUT = 28 * 28\n",
        "OUTPUT = 10\n",
        "\n",
        "model = nn.Sequential(nn.Flatten(),\n",
        "                      nn.Linear(INPUT, 256),\n",
        "                      nn.LeakyReLU(0.01),\n",
        "                      nn.Linear(256, 64),\n",
        "                      nn.LeakyReLU(0.01),\n",
        "                      nn.Linear(64, OUTPUT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_qfqDp2Z1X3"
      },
      "source": [
        "Aquí comienza el ejercicio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoBuc_TaepJq",
        "outputId": "c98f7495-1008-43e9-c052-4d66a1f6d029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------fold no---------0----------------------\n",
            "\n",
            "Fold 0:  Accuracy: 2551.0/5000 (51%)\n",
            "\n",
            "Fold 0:  Accuracy: 2566.0/5000 (51%)\n",
            "\n",
            "Fold 0:  Accuracy: 2924.0/5000 (58%)\n",
            "\n",
            "Fold 0:  Accuracy: 2954.0/5000 (59%)\n",
            "------------fold no---------1----------------------\n",
            "\n",
            "Fold 1:  Accuracy: 3173.0/5000 (63%)\n",
            "\n",
            "Fold 1:  Accuracy: 3149.0/5000 (63%)\n",
            "\n",
            "Fold 1:  Accuracy: 3526.0/5000 (71%)\n",
            "\n",
            "Fold 1:  Accuracy: 3374.0/5000 (67%)\n",
            "------------fold no---------0----------------------\n",
            "\n",
            "Fold 0:  Accuracy: 2343.0/5000 (47%)\n",
            "\n",
            "Fold 0:  Accuracy: 2352.0/5000 (47%)\n",
            "\n",
            "Fold 0:  Accuracy: 2596.0/5000 (52%)\n",
            "\n",
            "Fold 0:  Accuracy: 2557.0/5000 (51%)\n",
            "------------fold no---------1----------------------\n",
            "\n",
            "Fold 1:  Accuracy: 2323.0/5000 (46%)\n",
            "\n",
            "Fold 1:  Accuracy: 2244.0/5000 (45%)\n",
            "\n",
            "Fold 1:  Accuracy: 2123.0/5000 (42%)\n",
            "\n",
            "Fold 1:  Accuracy: 2082.0/5000 (42%)\n",
            "------------fold no---------0----------------------\n",
            "\n",
            "Fold 0:  Accuracy: 2396.0/5000 (48%)\n",
            "\n",
            "Fold 0:  Accuracy: 2394.0/5000 (48%)\n",
            "\n",
            "Fold 0:  Accuracy: 3023.0/5000 (60%)\n",
            "\n",
            "Fold 0:  Accuracy: 3108.0/5000 (62%)\n",
            "------------fold no---------1----------------------\n",
            "\n",
            "Fold 1:  Accuracy: 1804.0/5000 (36%)\n",
            "\n",
            "Fold 1:  Accuracy: 1885.0/5000 (38%)\n",
            "\n",
            "Fold 1:  Accuracy: 2794.0/5000 (56%)\n",
            "\n",
            "Fold 1:  Accuracy: 2799.0/5000 (56%)\n",
            "------------fold no---------0----------------------\n",
            "\n",
            "Fold 0:  Accuracy: 1803.0/5000 (36%)\n",
            "\n",
            "Fold 0:  Accuracy: 1856.0/5000 (37%)\n",
            "\n",
            "Fold 0:  Accuracy: 2163.0/5000 (43%)\n",
            "\n",
            "Fold 0:  Accuracy: 2136.0/5000 (43%)\n",
            "------------fold no---------1----------------------\n",
            "\n",
            "Fold 1:  Accuracy: 1296.0/5000 (26%)\n",
            "\n",
            "Fold 1:  Accuracy: 1250.0/5000 (25%)\n",
            "\n",
            "Fold 1:  Accuracy: 2028.0/5000 (41%)\n",
            "\n",
            "Fold 1:  Accuracy: 2051.0/5000 (41%)\n",
            "El mejor optimizador es Adagrad con una precisión de validación de 0.6328\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import optimizer\n",
        "INPUT = 28 * 28\n",
        "OUTPUT = 10\n",
        "\n",
        "def create_model(optimizer_name):\n",
        "  # Complete el código aquí\n",
        "  model = nn.Sequential(nn.Flatten(),\n",
        "                      nn.Linear(INPUT, 256),\n",
        "                      nn.LeakyReLU(0.01),\n",
        "                      nn.Linear(256, 64),\n",
        "                      nn.LeakyReLU(0.01),\n",
        "                      nn.Linear(64, OUTPUT))\n",
        "  optimizers = {\n",
        "      'Adagrad': torch.optim.Adagrad(model.parameters(), lr=0.3),\n",
        "      'RMSprop': torch.optim.RMSprop(model.parameters(), lr=0.3),\n",
        "      'Adadelta': torch.optim.Adadelta(model.parameters(), lr=0.3),\n",
        "      'Adam': torch.optim.Adam(model.parameters(), lr=0.3),\n",
        "  }\n",
        "\n",
        "  optimizer = optimizers[optimizer_name]\n",
        "  return model, optimizer\n",
        "\n",
        "data_iter = datasets.FashionMNIST(\n",
        "        root=\"../data\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "N_EPOCHS = 2\n",
        "N_FOLDS = 2\n",
        "optimizers = [\"Adagrad\", \"RMSprop\", \"Adadelta\", \"Adam\"]\n",
        "\n",
        "results = {}\n",
        "for opt_name in optimizers:\n",
        "  # Complete el código aquí\n",
        "  model, optimizer = create_model(opt_name)\n",
        "  train_acc, validation_acc = train_kfold(model, optimizer, data_iter, N_FOLDS, N_EPOCHS)\n",
        "  results[opt_name] = (np.array(train_acc).mean(), np.array(validation_acc).mean())\n",
        "\n",
        "\n",
        "best_optimizer = max(results, key=lambda opt: results[opt][1])\n",
        "print(f\"El mejor optimizador es {best_optimizer} con una precisión de validación de {results[best_optimizer][1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTVOWyEMVstj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
